{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis, LinearDiscriminantAnalysis\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tqdm import tqdm_notebook\n",
    "import warnings\n",
    "import multiprocessing\n",
    "from scipy.optimize import minimize  \n",
    "import time, os\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(262144, 258) (131073, 257)\n"
     ]
    }
   ],
   "source": [
    "# STEP 2\n",
    "path = os.getcwd()\n",
    "train = pd.read_csv(path + '/train.csv')\n",
    "test = pd.read_csv(path + '/test.csv')\n",
    "cols = [c for c in train.columns if c not in ['id', 'target', 'wheezy-copper-turtle-magic']]\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build first QDA model and predict test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As shown in [this kernel](https://www.kaggle.com/cdeotte/logistic-regression-0-800), 'wheezy-copper-turtle-magic' is a magic feature which interacts with other variables to predict the target. When wheezy-copper-turtle-magic equals a specific value, then other variables can predict the target well.\n",
    "### For example, Suppose we have data with two variables and one target: (x1,x2,y) with the following 4 rows: (0,0,0), (1,0,1), (0,1,1), (1,1,0). Notice that neither x1 nor x2 correlate with target y. Also x1 and x2 do not correlate with each other. However, x1 and x2 interact. Whenever x1 is not equal to x2 then y=1 and when x1=x2 then y=0. So together they predict y but separately they cannot predict y.\n",
    "### 'wheezy-copper-turtle-magic' has 512 different values, thats why we built 512 non-linear models in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5f353460bfa46fda382d17c21fa4e06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=512), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AUC: 0.96462\n"
     ]
    }
   ],
   "source": [
    "# STEP 3\n",
    "oof = np.zeros(len(train))\n",
    "preds = np.zeros(len(test))\n",
    "params = [{'reg_param': [0.1, 0.2, 0.3, 0.4, 0.5]}]\n",
    "# 512 models\n",
    "reg_params = np.zeros(512)\n",
    "for i in tqdm_notebook(range(512)):\n",
    "\n",
    "    train2 = train[train['wheezy-copper-turtle-magic']==i]\n",
    "    test2 = test[test['wheezy-copper-turtle-magic']==i]\n",
    "    idx1 = train2.index; idx2 = test2.index\n",
    "    train2.reset_index(drop=True,inplace=True)\n",
    "\n",
    "    data = pd.concat([pd.DataFrame(train2[cols]), pd.DataFrame(test2[cols])])\n",
    "    pipe = Pipeline([('vt', VarianceThreshold(threshold=1.5)), ('scaler', StandardScaler())])\n",
    "    data2 = pipe.fit_transform(data[cols])\n",
    "    train3 = data2[:train2.shape[0]]; test3 = data2[train2.shape[0]:]\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=11, random_state=42)\n",
    "    for train_index, test_index in skf.split(train2, train2['target']):\n",
    "\n",
    "        qda = QuadraticDiscriminantAnalysis()\n",
    "        clf = GridSearchCV(qda, params, cv=4)\n",
    "        clf.fit(train3[train_index,:],train2.loc[train_index]['target'])\n",
    "        reg_params[i] = clf.best_params_['reg_param']\n",
    "        oof[idx1[test_index]] = clf.predict_proba(train3[test_index,:])[:,1]\n",
    "        preds[idx2] += clf.predict_proba(test3)[:,1] / skf.n_splits\n",
    "\n",
    "auc = roc_auc_score(train['target'], oof)\n",
    "print(f'AUC: {auc:.5}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pseudo Labeling and build second model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train data set has 262144 rows in total, each of 512 models will be trained with 512 rows. To get better prediction, each model may need more data. With pseudo labeling, we can get an additional 400 rows of training data and increase CV and LB.\n",
    "### Pseudo labeling is the process of adding confident predicted test data to your training data. Pseudo labeling is a 5 step process. (1) Build a model using training data. (2) Predict labels for an unseen test dataset. (3) Add confident predicted test observations to our training data (4) Build a new model using combined data. And (5) use your new model to predict the test data and submit to Kaggle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111550 Test Records added for iteration :  0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e0922a6c8244f52bc2841f69b553772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=512), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AUC: 0.9711\n",
      "122374 Test Records added for iteration :  1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84454e188c00476990e08b2c0de430e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=512), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AUC: 0.97055\n",
      "123114 Test Records added for iteration :  2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "612229877eb24b3c857dd2ae7c9786f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=512), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AUC: 0.97049\n",
      "123225 Test Records added for iteration :  3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d7fed11e7084ba3a7dc9baf6a8f92e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=512), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# STEP 4\n",
    "for itr in range(4):\n",
    "    test['target'] = preds\n",
    "    test.loc[test['target'] > 0.90, 'target'] = 1 # initial 94\n",
    "    test.loc[test['target'] < 0.10, 'target'] = 0 # initial 06\n",
    "    usefull_test = test[(test['target'] == 1) | (test['target'] == 0)]\n",
    "    new_train = pd.concat([train, usefull_test]).reset_index(drop=True)\n",
    "    print(usefull_test.shape[0], \"Test Records added for iteration : \", itr)\n",
    "    new_train.loc[oof > 0.995, 'target'] = 1 # initial 98\n",
    "    new_train.loc[oof < 0.005, 'target'] = 0 # initial 02\n",
    "    oof2 = np.zeros(len(train))\n",
    "    preds = np.zeros(len(test))\n",
    "    for i in tqdm_notebook(range(512)):\n",
    "\n",
    "        train2 = new_train[new_train['wheezy-copper-turtle-magic']==i]\n",
    "        test2 = test[test['wheezy-copper-turtle-magic']==i]\n",
    "        idx1 = train[train['wheezy-copper-turtle-magic']==i].index\n",
    "        idx2 = test2.index\n",
    "        train2.reset_index(drop=True,inplace=True)\n",
    "\n",
    "        data = pd.concat([pd.DataFrame(train2[cols]), pd.DataFrame(test2[cols])])\n",
    "        pipe = Pipeline([('vt', VarianceThreshold(threshold=1.5)), ('scaler', StandardScaler())])\n",
    "        data2 = pipe.fit_transform(data[cols])\n",
    "        train3 = data2[:train2.shape[0]]\n",
    "        test3 = data2[train2.shape[0]:]\n",
    "\n",
    "        skf = StratifiedKFold(n_splits=11, random_state=time.time)\n",
    "        for train_index, test_index in skf.split(train2, train2['target']):\n",
    "            oof_test_index = [t for t in test_index if t < len(idx1)]\n",
    "            \n",
    "            clf = QuadraticDiscriminantAnalysis(reg_params[i])\n",
    "            clf.fit(train3[train_index,:],train2.loc[train_index]['target'])\n",
    "            if len(oof_test_index) > 0:\n",
    "                oof2[idx1[oof_test_index]] = clf.predict_proba(train3[oof_test_index,:])[:,1]\n",
    "            preds[idx2] += clf.predict_proba(test3)[:,1] / skf.n_splits\n",
    "    auc = roc_auc_score(train['target'], oof2)\n",
    "    print(f'AUC: {auc:.5}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 5\n",
    "sub = pd.read_csv( path + '/sample_submission.csv')\n",
    "sub['target'] = preds\n",
    "sub.to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
